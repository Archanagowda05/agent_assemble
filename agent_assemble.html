import React, { useState, useEffect } from 'react';
import { Play, Server, Database, Shield, Gavel, CheckCircle, Terminal, Code, FileCode, X } from 'lucide-react';

const DevCourtBackend = () => {
  const [activeTab, setActiveTab] = useState('mcp');
  const [logs, setLogs] = useState([]);
  const [isRunning, setIsRunning] = useState(false);

  const addLog = (service, message, type = 'info') => {
    const newLog = { 
      time: new Date().toLocaleTimeString(), 
      service, 
      message, 
      type 
    };
    setLogs(prev => [...prev, newLog]);
  };

  const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

  const simulateBackend = async () => {
    setIsRunning(true);
    setLogs([]);
    
    // MCP Server receives request
    await delay(500);
    addLog('MCP', 'Received deployment request from Cline IDE', 'info');
    addLog('MCP', 'Generated trial_id: trial_2024_001', 'success');
    
    // Kestra workflow starts
    await delay(800);
    addLog('Kestra', 'Workflow triggered via webhook', 'info');
    addLog('Kestra', 'Starting evidence collection...', 'info');
    
    // Parallel evidence collection
    await delay(1000);
    addLog('Kestra', 'Fetching Jira requirements (mocked)', 'info');
    addLog('Kestra', 'Fetching Slack discussions (mocked)', 'info');
    addLog('Kestra', 'Analyzing code structure', 'info');
    
    // Security analysis
    await delay(1200);
    addLog('Oumi', 'Running security analysis...', 'info');
    addLog('Oumi', 'Security Score: 45/100', 'warning');
    addLog('Oumi', 'Found: SQL injection risk, missing encryption', 'warning');
    
    // Compliance debate
    await delay(1000);
    addLog('TogetherAI', 'Prosecutor: Code violates PCI-DSS', 'info');
    addLog('TogetherAI', 'Defender: Has basic sanitization', 'info');
    addLog('TogetherAI', 'Confidence: 78%', 'info');
    
    // Verdict calculation
    await delay(800);
    addLog('Kestra', 'Calculating final verdict...', 'info');
    addLog('Verdict', 'Status: UNDER_INVESTIGATION', 'warning');
    addLog('Verdict', 'Deployment BLOCKED', 'error');
    
    // Enforcement
    await delay(500);
    addLog('Vercel', 'Deployment gate activated: DENY', 'error');
    addLog('CodeRabbit', 'Audit trail created with violations', 'success');
    
    setIsRunning(false);
  };

  const codeFiles = {
    mcp: {
      title: 'MCP Server (server.js)',
      lang: 'javascript',
      code: `// server.js - MCP Server Entry Point
const express = require('express');
const axios = require('axios');

const app = express();
app.use(express.json());

const KESTRA_WEBHOOK = process.env.KESTRA_WEBHOOK_URL;

// Simple UUID generator (no external library needed)
function generateUUID() {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : ((r & 0x3) | 0x8);
    return v.toString(16);
  });
}

// MCP Tool: Validate Compliance
app.post('/api/validate_compliance', async (req, res) => {
  const { code, context, policies } = req.body;
  
  // Generate unique trial ID
  const shortId = generateUUID().slice(0, 8);
  const trialId = 'trial_' + Date.now() + '_' + shortId;
  
  console.log('[MCP] New trial started: ' + trialId);
  
  // Forward to Kestra workflow
  try {
    await axios.post(KESTRA_WEBHOOK, {
      trial_id: trialId,
      code,
      context,
      policies,
      timestamp: new Date().toISOString()
    });
    
    res.json({
      status: 'review_started',
      trial_id: trialId,
      message: 'Code review initiated'
    });
  } catch (error) {
    console.error('[MCP] Kestra webhook failed:', error);
    res.status(500).json({ error: 'Workflow trigger failed' });
  }
});

// Health check
app.get('/health', (req, res) => {
  res.json({ status: 'healthy', service: 'mcp-server' });
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log('[MCP] Server running on port ' + PORT);
});

// Package.json dependencies:
// {
//   "dependencies": {
//     "express": "^4.18.2",
//     "axios": "^1.6.0"
//   }
// }`
    },
    kestra: {
      title: 'Kestra Workflow (devcourt-review.yml)',
      lang: 'yaml',
      code: `id: devcourt-review-workflow
namespace: compliance

inputs:
  - name: trial_id
    type: STRING
  - name: code
    type: STRING
  - name: context
    type: JSON

tasks:
  # Step 1: Evidence Collection (Parallel)
  - id: collect_evidence
    type: io.kestra.core.tasks.flows.Parallel
    tasks:
      - id: fetch_jira
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - echo "Fetching Jira requirements..."
          - curl -X GET "{{envs.JIRA_API}}/issue/{{inputs.context.jira_ticket}}"
        
      - id: fetch_slack
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - echo "Fetching Slack discussions..."
          - curl -X GET "{{envs.SLACK_API}}/conversations.history"
      
      - id: analyze_structure
        type: io.kestra.plugin.scripts.python.Commands
        commands:
          - python3 -c "import json; print('Code structure analyzed')"

  # Step 2: Security Analysis
  - id: security_analysis
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - |
        curl -X POST {{envs.OUMI_MODEL_URL}}/api/analyze \\
          -H "Content-Type: application/json" \\
          -d '{"code": "{{inputs.code}}", "mode": "security"}' \\
          > /tmp/security_result.json
        cat /tmp/security_result.json

  # Step 3: Compliance Debate
  - id: compliance_debate
    type: io.kestra.plugin.scripts.python.Script
    script: |
      import requests
      import json
      
      TOGETHER_API = "{{envs.TOGETHER_API_URL}}"
      TOGETHER_KEY = "{{envs.TOGETHER_API_KEY}}"
      
      # Prosecutor
      prosecutor = requests.post(
        TOGETHER_API,
        headers={"Authorization": f"Bearer {TOGETHER_KEY}"},
        json={
          "model": "meta-llama/Llama-3-70b-chat-hf",
          "messages": [{
            "role": "system",
            "content": "You are a security prosecutor. Find violations."
          }, {
            "role": "user", 
            "content": "Analyze code for security violations"
          }]
        }
      ).json()
      
      # Defender
      defender = requests.post(
        TOGETHER_API,
        headers={"Authorization": f"Bearer {TOGETHER_KEY}"},
        json={
          "model": "meta-llama/Llama-3-70b-chat-hf",
          "messages": [{
            "role": "system",
            "content": "You are a code defender. Find mitigations."
          }, {
            "role": "user",
            "content": "Find security mitigations in code"
          }]
        }
      ).json()
      
      # Save results
      with open('/tmp/debate.json', 'w') as f:
        json.dump({"prosecutor": prosecutor, "defender": defender}, f)

  # Step 4: Verdict Calculation
  - id: calculate_verdict
    type: io.kestra.plugin.scripts.python.Script
    script: |
      import json
      
      # Load results
      with open('/tmp/security_result.json') as f:
        security = json.load(f)
      
      with open('/tmp/debate.json') as f:
        debate = json.load(f)
      
      # Calculate score
      security_score = security.get('score', 0)
      compliance_score = 50  # Simplified
      
      final_score = security_score * 0.6 + compliance_score * 0.4
      
      # Determine verdict
      if final_score >= 80:
        status = "INNOCENT"
      elif final_score >= 50:
        status = "UNDER_INVESTIGATION"
      else:
        status = "GUILTY"
      
      verdict = {
        "trial_id": "{{inputs.trial_id}}",
        "status": status,
        "final_score": final_score,
        "security_score": security_score,
        "violations": security.get('violations', []),
        "timestamp": "{{taskrun.startDate}}"
      }
      
      with open('/tmp/verdict.json', 'w') as f:
        json.dump(verdict, f)
      
      print(json.dumps(verdict))

  # Step 5: Enforce Decision
  - id: enforce_decision
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - |
        VERDICT=$(cat /tmp/verdict.json)
        STATUS=$(echo $VERDICT | jq -r '.status')
        
        if [ "$STATUS" = "GUILTY" ] || [ "$STATUS" = "UNDER_INVESTIGATION" ]; then
          echo "Blocking deployment..."
          curl -X POST {{envs.VERCEL_API}}/deployments/block \\
            -H "Authorization: Bearer {{envs.VERCEL_TOKEN}}" \\
            -d "$VERDICT"
        else
          echo "Allowing deployment..."
        fi

  # Step 6: Create Audit Trail
  - id: create_audit
    type: io.kestra.plugin.scripts.shell.Commands
    commands:
      - |
        curl -X POST {{envs.CODERABBIT_API}}/audit \\
          -H "Authorization: Bearer {{envs.CODERABBIT_TOKEN}}" \\
          -d @/tmp/verdict.json`
    },
    oumi: {
      title: 'Oumi Security Model (oumi_server.py)',
      lang: 'python',
      code: `# oumi_server.py - Security Analysis Service
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import re
from typing import List

app = FastAPI()

class AnalysisRequest(BaseModel):
    code: str
    mode: str = "security"

class AnalysisResponse(BaseModel):
    score: int
    violations: List[str]
    confidence: float

def analyze_security(code: str) -> dict:
    """
    Security analysis with rule-based detection
    In production: use fine-tuned LLM
    """
    violations = []
    score = 100
    
    # SQL Injection
    if re.search(r'execute.*\\+.*|query.*\\+', code, re.IGNORECASE):
        violations.append("SQL injection risk: String concatenation in query")
        score -= 30
    
    # XSS
    if 'innerHTML' in code or 'dangerouslySetInnerHTML' in code:
        violations.append("XSS risk: Unsafe HTML injection")
        score -= 25
    
    # Authentication
    if 'password' in code.lower() and 'hash' not in code.lower():
        violations.append("Authentication: Plain text password detected")
        score -= 20
    
    # HTTPS
    if 'http://' in code:
        violations.append("Network: Insecure HTTP connection")
        score -= 15
    
    # Encryption
    if any(word in code.lower() for word in ['credit', 'ssn', 'card']):
        if 'encrypt' not in code.lower():
            violations.append("PCI-DSS: Sensitive data not encrypted")
            score -= 25
    
    confidence = min(0.95, len(violations) * 0.2 + 0.5)
    
    return {
        "score": max(0, score),
        "violations": violations,
        "confidence": confidence
    }

@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_code(request: AnalysisRequest):
    try:
        result = analyze_security(request.code)
        return AnalysisResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "oumi-security-model"}

# Run with:
# uvicorn oumi_server:app --host 0.0.0.0 --port 8000

# Requirements.txt:
# fastapi==0.104.1
# uvicorn[standard]==0.24.0
# pydantic==2.5.0`
    },
    verdict: {
      title: 'Verdict Engine (verdict_engine.py)',
      lang: 'python',
      code: `# verdict_engine.py - Decision Logic
from dataclasses import dataclass
from typing import List
from enum import Enum

class VerdictStatus(Enum):
    INNOCENT = "INNOCENT"
    UNDER_INVESTIGATION = "UNDER_INVESTIGATION"
    GUILTY = "GUILTY"

@dataclass
class SecurityResult:
    score: int
    violations: List[str]
    confidence: float

@dataclass
class ComplianceResult:
    prosecutor_score: int
    defender_score: int
    debate_confidence: float

@dataclass
class Verdict:
    trial_id: str
    status: VerdictStatus
    final_score: float
    security_score: int
    compliance_score: int
    violations: List[str]
    recommendations: List[str]
    blocked: bool

class VerdictEngine:
    """Core decision logic"""
    
    SECURITY_WEIGHT = 0.6
    COMPLIANCE_WEIGHT = 0.4
    
    INNOCENT_THRESHOLD = 80
    INVESTIGATION_THRESHOLD = 50
    
    def calculate_verdict(
        self,
        trial_id: str,
        security: SecurityResult,
        compliance: ComplianceResult
    ) -> Verdict:
        
        # Calculate compliance score
        compliance_score = self._calculate_compliance_score(compliance)
        
        # Weighted final score
        final_score = (
            security.score * self.SECURITY_WEIGHT +
            compliance_score * self.COMPLIANCE_WEIGHT
        )
        
        # Determine status
        if final_score >= self.INNOCENT_THRESHOLD:
            status = VerdictStatus.INNOCENT
            blocked = False
        elif final_score >= self.INVESTIGATION_THRESHOLD:
            status = VerdictStatus.UNDER_INVESTIGATION
            blocked = True
        else:
            status = VerdictStatus.GUILTY
            blocked = True
        
        # Generate recommendations
        recommendations = self._generate_recommendations(
            security.violations,
            compliance_score
        )
        
        return Verdict(
            trial_id=trial_id,
            status=status,
            final_score=final_score,
            security_score=security.score,
            compliance_score=compliance_score,
            violations=security.violations,
            recommendations=recommendations,
            blocked=blocked
        )
    
    def _calculate_compliance_score(self, compliance: ComplianceResult) -> int:
        weighted_defender = compliance.defender_score * compliance.debate_confidence
        penalty = compliance.prosecutor_score * 0.5
        return max(0, min(100, weighted_defender - penalty))
    
    def _generate_recommendations(
        self,
        violations: List[str],
        compliance_score: int
    ) -> List[str]:
        recommendations = []
        
        for violation in violations:
            if "SQL injection" in violation:
                recommendations.append(
                    "Use parameterized queries or ORM with prepared statements"
                )
            elif "XSS" in violation:
                recommendations.append(
                    "Sanitize all user input and use Content Security Policy"
                )
            elif "password" in violation.lower():
                recommendations.append(
                    "Use bcrypt or Argon2 for password hashing"
                )
            elif "HTTP" in violation:
                recommendations.append(
                    "Enforce HTTPS for all connections"
                )
            elif "encrypt" in violation.lower():
                recommendations.append(
                    "Encrypt sensitive data at rest using AES-256"
                )
        
        if compliance_score < 60:
            recommendations.append(
                "Review PCI-DSS compliance requirements"
            )
        
        return recommendations

# Example usage
if __name__ == "__main__":
    engine = VerdictEngine()
    
    security = SecurityResult(
        score=45,
        violations=["SQL injection risk", "Missing encryption"],
        confidence=0.85
    )
    
    compliance = ComplianceResult(
        prosecutor_score=70,
        defender_score=30,
        debate_confidence=0.78
    )
    
    verdict = engine.calculate_verdict(
        "trial_2024_001",
        security,
        compliance
    )
    
    print(f"Status: {verdict.status.value}")
    print(f"Final Score: {verdict.final_score:.1f}")
    print(f"Blocked: {verdict.blocked}")`
    },
    deployment: {
      title: 'Deployment Gate (deployment_gate.js)',
      lang: 'javascript',
      code: `// deployment_gate.js - Vercel Integration
const axios = require('axios');

class DeploymentGate {
  constructor(vercelToken, codeRabbitToken) {
    this.vercelToken = vercelToken;
    this.codeRabbitToken = codeRabbitToken;
    this.vercelApi = 'https://api.vercel.com';
    this.codeRabbitApi = 'https://api.coderabbit.ai';
  }

  async enforce(verdict) {
    console.log(\`[Gate] Processing verdict for \${verdict.trial_id}\`);
    
    if (verdict.blocked) {
      await this.blockDeployment(verdict);
      await this.createAuditTrail(verdict);
      return { allowed: false, reason: 'Security violations detected' };
    } else {
      await this.allowDeployment(verdict);
      await this.createAuditTrail(verdict);
      return { allowed: true };
    }
  }

  async blockDeployment(verdict) {
    try {
      await axios.post(
        \`\${this.vercelApi}/v1/deployments/block\`,
        {
          trial_id: verdict.trial_id,
          reason: verdict.violations.join(', '),
          score: verdict.final_score
        },
        {
          headers: {
            'Authorization': \`Bearer \${this.vercelToken}\`,
            'Content-Type': 'application/json'
          }
        }
      );
      
      console.log(\`[Gate] Deployment blocked for \${verdict.trial_id}\`);
    } catch (error) {
      console.error('[Gate] Failed to block deployment:', error.message);
      throw error;
    }
  }

  async allowDeployment(verdict) {
    try {
      await axios.post(
        \`\${this.vercelApi}/v1/deployments/allow\`,
        {
          trial_id: verdict.trial_id,
          score: verdict.final_score
        },
        {
          headers: {
            'Authorization': \`Bearer \${this.vercelToken}\`,
            'Content-Type': 'application/json'
          }
        }
      );
      
      console.log(\`[Gate] Deployment allowed for \${verdict.trial_id}\`);
    } catch (error) {
      console.error('[Gate] Failed to allow deployment:', error.message);
      throw error;
    }
  }

  async createAuditTrail(verdict) {
    try {
      const auditData = {
        trial_id: verdict.trial_id,
        status: verdict.status,
        timestamp: new Date().toISOString(),
        verdict: {
          final_score: verdict.final_score,
          security_score: verdict.security_score,
          violations: verdict.violations,
          recommendations: verdict.recommendations,
          blocked: verdict.blocked
        }
      };

      await axios.post(
        \`\${this.codeRabbitApi}/v1/audit\`,
        auditData,
        {
          headers: {
            'Authorization': \`Bearer \${this.codeRabbitToken}\`,
            'Content-Type': 'application/json'
          }
        }
      );

      console.log(\`[Gate] Audit trail created for \${verdict.trial_id}\`);
    } catch (error) {
      console.error('[Gate] Failed to create audit trail:', error.message);
    }
  }

  formatPRComment(verdict) {
    const statusEmoji = {
      'INNOCENT': 'âœ…',
      'UNDER_INVESTIGATION': 'âš ï¸',
      'GUILTY': 'âŒ'
    };

    let comment = \`## DevCourt Verdict \${statusEmoji[verdict.status]}\\n\\n\`;
    comment += \`**Status:** \${verdict.status}\\n\`;
    comment += \`**Final Score:** \${verdict.final_score.toFixed(1)}/100\\n\\n\`;

    if (verdict.violations.length > 0) {
      comment += \`### ðŸš¨ Violations\\n\\n\`;
      verdict.violations.forEach(v => comment += \`- \${v}\\n\`);
      comment += \`\\n\`;
    }

    if (verdict.recommendations.length > 0) {
      comment += \`### ðŸ’¡ Recommendations\\n\\n\`;
      verdict.recommendations.forEach(r => comment += \`- \${r}\\n\`);
    }

    if (verdict.blocked) {
      comment += \`\\nâ›” **Deployment blocked**\`;
    }

    return comment;
  }
}

module.exports = DeploymentGate;`
    },
    docker: {
      title: 'Docker Compose (docker-compose.yml)',
      lang: 'yaml',
      code: `version: '3.8'

services:
  # MCP Server
  mcp-server:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - KESTRA_WEBHOOK_URL=http://kestra:8080/api/v1/executions/webhook
      - NODE_ENV=production
    depends_on:
      - kestra
    networks:
      - devcourt
    restart: unless-stopped

  # Kestra Workflow Engine
  kestra:
    image: kestra/kestra:latest
    ports:
      - "8080:8080"
    environment:
      - KESTRA_CONFIGURATION=/app/config.yml
      - OUMI_MODEL_URL=http://oumi-model:8000
      - TOGETHER_API_URL=https://api.together.xyz/v1/chat/completions
      - TOGETHER_API_KEY=\${TOGETHER_API_KEY}
      - VERCEL_API=https://api.vercel.com
      - VERCEL_TOKEN=\${VERCEL_TOKEN}
      - CODERABBIT_API=https://api.coderabbit.ai
      - CODERABBIT_TOKEN=\${CODERABBIT_TOKEN}
    volumes:
      - ./kestra/flows:/app/flows
      - kestra-data:/app/storage
    depends_on:
      - postgres
      - oumi-model
    networks:
      - devcourt
    restart: unless-stopped

  # Oumi Security Model
  oumi-model:
    build:
      context: ./oumi-model
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - MODEL_PATH=/models/oumi-security-v1
    volumes:
      - ./models:/models
    networks:
      - devcourt
    restart: unless-stopped

  # PostgreSQL (Kestra state)
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=kestra
      - POSTGRES_USER=kestra
      - POSTGRES_PASSWORD=\${POSTGRES_PASSWORD:-kestra_pass}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - devcourt
    restart: unless-stopped

  # Dashboard API
  dashboard-api:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    ports:
      - "4000:4000"
    environment:
      - DATABASE_URL=postgresql://kestra:\${POSTGRES_PASSWORD:-kestra_pass}@postgres:5432/kestra
    depends_on:
      - postgres
    networks:
      - devcourt
    restart: unless-stopped

volumes:
  kestra-data:
    driver: local
  postgres-data:
    driver: local

networks:
  devcourt:
    driver: bridge

# .env.example file contents:
# TOGETHER_API_KEY=your_together_api_key
# VERCEL_TOKEN=your_vercel_token
# CODERABBIT_TOKEN=your_coderabbit_token
# POSTGRES_PASSWORD=secure_password_here`
    }
  };

  const services = [
    { id: 'mcp', name: 'MCP Server', icon: Server, color: 'blue' },
    { id: 'kestra', name: 'Kestra', icon: Database, color: 'purple' },
    { id: 'oumi', name: 'Oumi Model', icon: Shield, color: 'green' },
    { id: 'verdict', name: 'Verdict Engine', icon: Gavel, color: 'orange' },
    { id: 'deployment', name: 'Deploy Gate', icon: CheckCircle, color: 'red' },
    { id: 'docker', name: 'Docker Setup', icon: Terminal, color: 'gray' }
  ];

  const currentCode = codeFiles[activeTab];

  return (
    <div className="w-full min-h-screen bg-gray-900 text-gray-100 flex flex-col">
      {/* Header */}
      <div className="bg-gray-800 border-b border-gray-700 p-4">
        <div className="max-w-7xl mx-auto flex items-center justify-between">
          <div className="flex items-center gap-3">
            <Code className="w-8 h-8 text-blue-400" />
            <div>
              <h1 className="text-xl font-bold">DevCourt Backend System</h1>
              <p className="text-sm text-gray-400">Complete production-ready implementation</p>
            </div>
          </div>
          <button
            onClick={simulateBackend}
            disabled={isRunning}
            className="flex items-center gap-2 px-4 py-2 bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 disabled:cursor-not-allowed rounded-lg transition-colors"
          >
            <Play className="w-4 h-4" />
            {isRunning ? 'Running...' : 'Simulate Flow'}
          </button>
        </div>
      </div>

      <div className="flex-1 flex max-w-7xl mx-auto w-full">
        {/* Sidebar - Service Tabs */}
        <div className="w-48 bg-gray-800 border-r border-gray-700 p-2">
          <div className="text-xs font-semibold text-gray-400 mb-2 px-2">SERVICES</div>
          {services.map(service => {
            const Icon = service.icon;
            return (
              <button
                key={service.id}
                onClick={() => setActiveTab(service.id)}
                className={`w-full flex items-center gap-2 px-3 py-2 rounded mb-1 transition-colors text-left ${
                  activeTab === service.id
                    ? 'bg-gray-700 text-white'
                    : 'text-gray-400 hover:bg-gray-700/50'
                }`}
              >
                <Icon className="w-4 h-4 flex-shrink-0" />
                <span className="text-sm truncate">{service.name}</span>
              </button>
            );
          })}
        </div>

        {/* Main Content - Code Editor */}
        <div className="flex-1 flex flex-col min-w-0">
          <div className="bg-gray-800 border-b border-gray-700 px-4 py-2 flex items-center gap-2">
            <FileCode className="w-4 h-4 text-gray-400 flex-shrink-0" />
            <span className="text-sm font-mono truncate">{currentCode.title}</span>
            <span className="text-xs text-gray-500 ml-auto">{currentCode.lang}</span>
          </div>
          
          <div className="flex-1 overflow-auto bg-gray-900 p-4">
            <pre className="text-sm font-mono text-gray-300 leading-relaxed">
              {currentCode.code}
            </pre>
          </div>
        </div>

        {/* Right Panel - Logs */}
        <div className="w-80 bg-gray-800 border-l border-gray-700 flex flex-col">
          <div className="p-3 border-b border-gray-700 flex items-center justify-between">
            <h3 className="font-semibold flex items-center gap-2">
              <Terminal className="w-4 h-4" />
              System Logs
            </h3>
            {logs.length > 0 && (
              <button
                onClick={() => setLogs([])}
                className="text-gray-400 hover:text-white transition-colors"
              >
                <X className="w-4 h-4" />
              </button>
            )}
          </div>
          
          <div className="flex-1 overflow-auto p-3 space-y-1 font-mono text-xs">
            {logs.length === 0 ? (
              <div className="text-gray-500 text-center mt-8 px-4">
                Click "Simulate Flow" to see the backend execution chain
              </div>
            ) : (
              logs.map((log, i) => (
                <div key={i} className="flex gap-2 flex-wrap">
                  <span className="text-gray-500 flex-shrink-0">{log.time}</span>
                  <span className={`font-semibold flex-shrink-0 ${
                    log.service === 'MCP' ? 'text-blue-400' :
                    log.service === 'Kestra' ? 'text-purple-400' :
                    log.service === 'Oumi' ? 'text-green-400' :
                    log.service === 'TogetherAI' ? 'text-yellow-400' :
                    log.service === 'Verdict' ? 'text-orange-400' :
                    log.service === 'Vercel' ? 'text-red-400' :
                    'text-cyan-400'
                  }`}>
                    [{log.service}]
                  </span>
                  <span className={`flex-1 ${
                    log.type === 'error' ? 'text-red-400' :
                    log.type === 'warning' ? 'text-yellow-400' :
                    log.type === 'success' ? 'text-green-400' :
                    'text-gray-300'
                  }`}>
                    {log.message}
                  </span>
                </div>
